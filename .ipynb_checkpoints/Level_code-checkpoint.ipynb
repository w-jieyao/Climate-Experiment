{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Model\n",
    "\n",
    "Notebook by: Jieyao Wang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding up the model under the new setting; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from supportfunctions import *\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for now set the damage function to be the low damage case only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damage function choices\n",
    "damageSpec = 'Low'  # Choose among \"High\"(Weitzman), 'Low'(Nordhaus) and 'Weighted' (arithmeticAverage of the two)\n",
    "\n",
    "if damageSpec == 'High':\n",
    "    weight = 0.0\n",
    "elif damageSpec == 'Low':\n",
    "    weight = 1.0\n",
    "else:\n",
    "    weight = 0.5\n",
    "\n",
    "xi_a =  1000  # Ambiguity Averse Paramter \n",
    "\n",
    "if xi_a < 1:\n",
    "    aversespec = \"Averse\"\n",
    "else:\n",
    "    aversespec = 'Neutral'\n",
    "\n",
    "smart_guess = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do list for consumption model\n",
    "\n",
    "change drift for D in uncertainty\\\n",
    "change flow utility term\\\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter set up-add in new parameter for temperature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "McD = np.loadtxt('./data/TCRE_MacDougallEtAl2017_update.txt')\n",
    "par_lambda_McD = McD / 1000\n",
    "\n",
    "beta_f = np.mean(par_lambda_McD)  # Climate sensitivity parameter, MacDougall (2017)\n",
    "sigma_f = np.var(par_lambda_McD, ddof = 1)  # varaiance of climate sensitivity parameters\n",
    "lambda_f = 1.0 / sigma_f \n",
    "\n",
    "# define global variables\n",
    "delta = 0.01        \n",
    "kappa = 0.032       \n",
    "sigma_k = 0.0161\n",
    "sigma_r = 0.0339 \n",
    "alpha = 0.115000000000000\n",
    "phi_0 = 0.0600\n",
    "phi_1 = 16.666666666666668\n",
    "mu_k = -0.034977443912449\n",
    "psi_0 = 0.112733407891680\n",
    "psi_1 = 0.142857142857143\n",
    "\n",
    "# parameters for damage function settings\n",
    "power = 2 \n",
    "gamma_1 = 0.00017675\n",
    "gamma_2 = 2. * 0.0022\n",
    "gamma_2_plus = 2. * 0.0197\n",
    "bar_gamma_2_plus = weight * 0 + (1 - weight) * gamma_2_plus\n",
    "\n",
    "sigma_1 = 0\n",
    "sigma_2 = 0\n",
    "rho_12 = 0\n",
    "F_bar = 2\n",
    "crit = 2\n",
    "F0 = 1\n",
    "\n",
    "xi_d = -1 * (1 - kappa)\n",
    "xi_k = -1 * (1 - kappa)\n",
    "\n",
    "epsilon = 0.3\n",
    "tol = 1e-8\n",
    "\n",
    "### arbitrary assumption on kappa\n",
    "kappa_mean = 1\n",
    "kappa_var = 0.1\n",
    "c_temp = 3.154e8\n",
    "k_temp = 1 # placeholder value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state space set up-adjust K to T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_min = 0\n",
    "R_max = 9\n",
    "F_min = 0\n",
    "F_max = 4000\n",
    "T_min = 200\n",
    "T_max = 350\n",
    "\n",
    "hR = 0.5\n",
    "hF = 100\n",
    "hT = 20\n",
    "\n",
    "R = np.arange(R_min, R_max + hR, hR)\n",
    "nR = len(R)\n",
    "F = np.arange(F_min, F_max + hF, hF)\n",
    "nF = len(F)\n",
    "T = np.arange(T_min, T_max + hT, hT)\n",
    "nT = len(T)\n",
    "\n",
    "(R_mat, F_mat, T_mat) = np.meshgrid(R,F,T, indexing = 'ij')\n",
    "stateSpace = np.hstack([R_mat.reshape(-1,1,order = 'F'),F_mat.reshape(-1,1,order = 'F'),T_mat.reshape(-1,1,order = 'F')])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other numerical assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrature = 'legendre'\n",
    "n = 30\n",
    "a = beta_f - 5 * np.sqrt(sigma_f)\n",
    "b = beta_f + 5 * np.sqrt(sigma_f)\n",
    "\n",
    "FC_Err = 1\n",
    "episode = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and update_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    v0 = kappa * R_mat - sigma_f * F_mat\n",
    "    e0 = update_e\n",
    "    \n",
    "    return v0, e0\n",
    "\n",
    "def update_e(V = v0):\n",
    "    V_r = finiteDiff(V,0,1,hR)\n",
    "    V_r[V_r < 1e-16] = 1e-16\n",
    "    V_f = finiteDiff(V,1,1,hF)\n",
    "    e = (delta * kappa) / ((V_r - V_f) * np.exp(R_mat) )\n",
    "    return e\n",
    "\n",
    "\n",
    "def g_1_func():\n",
    "    c_1 = .15\n",
    "    c_2 = .7\n",
    "    c = 3.154e8\n",
    "    # T_0 = (1.9e-15) ** (-1/6)\n",
    "    T_0 = 288.05\n",
    "    T_c = 273\n",
    "    Q_0 = 342.5-.5\n",
    "    # Q_0 = 342.5+.5\n",
    "    sigma_ZG = 5.6697e-8\n",
    "    m = .4\n",
    "    mu = 1\n",
    "\n",
    "    g1 = (mu * Q_0 * (1 - c_1 - c_2/2) - sigma_ZG * (T_mat) ** 4 * (1 - m * np.tanh((T_mat / T_0) ** 6))) / c\n",
    "    return g1\n",
    "    \n",
    "def g_2_func(kappa_ZG = 1):\n",
    "    c_1 = .15\n",
    "    c_2 = .7\n",
    "    c = 3.154e8\n",
    "    # T_0 = (1.9e-15) ** (-1/6)\n",
    "    T_0 = 288.05\n",
    "    T_c = 273\n",
    "    Q_0 = 342.5-.5\n",
    "    # Q_0 = 342.5+.5\n",
    "    sigma_ZG = 5.6697e-8\n",
    "    m = .4\n",
    "    mu = 1\n",
    "\n",
    "    g2 = (mu * Q_0 * (c_2/2) * np.tanh(kappa_ZG * (T_mat - T_c))) / c\n",
    "    return g2\n",
    "\n",
    "def num_1(kappa_ZG = 1):\n",
    "    global v0\n",
    "    v0_dt = finiteDiff(v0,2,1,hT)\n",
    "    num1 = np.exp((-1/xi_p) * (xi_d * (gamma_1 + gamma_2 * T_mat) + v0_dt) * (g_2_func(kappa_ZG))\n",
    "    \n",
    "    return num1\n",
    "\n",
    "def prior_kappa(kappa_ZG):\n",
    "    \n",
    "    # here plug in whatever prior of the kappa function decide to be\n",
    "    # but to use the quadrature must assume prior is a normal    \n",
    "    return kappa_ZG\n",
    "\n",
    "def scale_1_func(x):\n",
    "    # we need to decide the mean and variance of kappa\n",
    "    return num_1(x) * norm.pdf(x,kappa_mean,np.sqrt(kappa_var))\n",
    "  \n",
    "def I_1():\n",
    "    scale_1 = quad_int(scale_1_fnc, a, b, n, 'legendre')\n",
    "    return -xi_p * np.log(scale_1)\n",
    "\n",
    "def J_1():\n",
    "    scale_1 = quad_int(scale_1_fnc, a, b, n, 'legendre')\n",
    "    J1 = ((xi_d * (gamma_1 + gamma_2 * T_mat) + v0_dt) \\\n",
    "           * quad_int(g_2_func * scale_1_func, a, b, n, 'legendre')) / (scale_1)\n",
    "    return J1\n",
    "\n",
    "def R_1():\n",
    "    return 1/xi_p * (I_1() - J_1())\n",
    "\n",
    "\n",
    "def const_flow():\n",
    "    global v0\n",
    "    v0_dt = finiteDiff(v0,2,1,hT)\n",
    "    flow = v0_dt * g_1_func() \\\n",
    "    + v0_dt * (k_temp/c_temp) * np.log(F_mat / F_0) \\\n",
    "    + (xi_d * (gamma_1 + gamma_2 * T_mat) * (k_temp/c_temp) * np.log(F_mat / F_0)) \\\n",
    "    + xi_d * (gamma_1 + gamma_2 * T_mat) * g_1_func()\n",
    "    return flow\n",
    "\n",
    "\n",
    "### left to code up the second model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "while episode == 0 or FC_Err > tol: \n",
    "    vold = v0.copy()\n",
    "    \n",
    "    ### so every loop the value of v0 will also be updated all along\n",
    "    ### no need to use V as an function input\n",
    "    \n",
    "    if episode > 2000:\n",
    "        epsilon = 0.1\n",
    "    elif episode > 1000:\n",
    "        epsilon = 0.2\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#### restart\n",
    "\n",
    "    initialize()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### so need to work on the uncertainty\n",
    "#### no cobweb or i or j at all    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        e_hat = e_star\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    a1 = np.zeros(R_mat.shape)\n",
    "    b1 = xi_d * e_hat * np.exp(R_mat) * Œ≥1\n",
    "    c1 = 2 * xi_d * e_hat * np.exp(R_mat) * F_mat * Œ≥2 \n",
    "    ŒªÃÉ1 = Œª + c1 / Œæp\n",
    "    Œ≤ÃÉ1 = Œ≤ùòß - c1 * Œ≤ùòß / (Œæp * ŒªÃÉ1) -  b1 /  (Œæp * ŒªÃÉ1)\n",
    "    I1 = a1 - 0.5 * np.log(Œª) * Œæp + 0.5 * np.log(ŒªÃÉ1) * Œæp + 0.5 * Œª * Œ≤ùòß ** 2 * Œæp - 0.5 * ŒªÃÉ1 * (Œ≤ÃÉ1) ** 2 * Œæp\n",
    "    R1 = 1 / Œæp * (I1 - (a1 + b1 * Œ≤ÃÉ1 + c1 / 2 * Œ≤ÃÉ1 ** 2 + c1 / 2 / ŒªÃÉ1))\n",
    "    J1_without_e = xi_d * (Œ≥1 * Œ≤ÃÉ1 + Œ≥2 * F_mat * (Œ≤ÃÉ1 ** 2 + 1 / ŒªÃÉ1)) * np.exp(R_mat)\n",
    "\n",
    "    œÄÃÉ1 = weight * np.exp(-1 / Œæp * I1)\n",
    "\n",
    "    # Step (2), solve minimization problem in HJB and calculate drift distortion\n",
    "    # See remark 2.1.3 for more details\n",
    "    def scale_2_fnc(x):\n",
    "        return np.exp(-1 / Œæp * xi_d * (Œ≥1 * x + Œ≥2 * x ** 2 * F_mat + Œ≥2_plus * x * (x * F_mat - FÃÑ) ** (power - 1) * ((x * F_mat - FÃÑ) >= 0)) * np.exp(R_mat) * e_hat)  * norm.pdf(x,Œ≤ùòß,np.sqrt(œÉ·µ¶))\n",
    "\n",
    "    scale_2 = quad_int(scale_2_fnc, a, b, n, 'legendre')\n",
    "\n",
    "    def q2_tilde_fnc(x):\n",
    "        return np.exp(-1 / Œæp * xi_d * (Œ≥1 * x + Œ≥2 * x ** 2 * F_mat + Œ≥2_plus * x * (x * F_mat - FÃÑ) ** (power - 1) * ((x * F_mat - FÃÑ) >= 0)) * np.exp(R_mat) * e_hat) / scale_2\n",
    "\n",
    "    I2 = -1 * Œæp * np.log(scale_2)\n",
    "\n",
    "    def J2_without_e_fnc(x):\n",
    "        return xi_d * np.exp(R_mat) * q2_tilde_fnc(x) * (Œ≥1 * x + Œ≥2 * F_mat * x ** 2 + Œ≥2_plus * x * (x * F_mat - FÃÑ) ** (power - 1) * ((x * F_mat - FÃÑ) >= 0)) * norm.pdf(x,Œ≤ùòß,np.sqrt(œÉ·µ¶))\n",
    "\n",
    "    J2_without_e = quad_int(J2_without_e_fnc, a, b, n, 'legendre')\n",
    "    J2_with_e = J2_without_e * e_hat\n",
    "\n",
    "    R2 = (I2 - J2_with_e) / Œæp\n",
    "    œÄÃÉ2 = (1 - weight) * np.exp(-1 / Œæp * I2)\n",
    "    œÄÃÉ1_norm = œÄÃÉ1 / (œÄÃÉ1 + œÄÃÉ2)\n",
    "    œÄÃÉ2_norm = 1 - œÄÃÉ1_norm\n",
    "\n",
    "    # step 4 (b) updating e based on first order conditions\n",
    "    expec_e_sum = (œÄÃÉ1_norm * J1_without_e + œÄÃÉ2_norm * J2_without_e)\n",
    "\n",
    "    B1 = v0_dr - v0_df * np.exp(R_mat) - expec_e_sum\n",
    "    C1 = -Œ¥ * Œ∫\n",
    "    e = -C1 / B1\n",
    "    e_star = e\n",
    "\n",
    "    J1 = J1_without_e * e_star\n",
    "    J2 = J2_without_e * e_star\n",
    "\n",
    "    # Step (3) calculating implied entropies\n",
    "    I_term = -1 * Œæp * np.log(œÄÃÉ1 + œÄÃÉ2)\n",
    "\n",
    "    R1 = (I1 - J1) / Œæp\n",
    "    R2 = (I2 - J2) / Œæp\n",
    "    \n",
    "    # Step (5) solving for adjusted drift\n",
    "    drift_distort = (œÄÃÉ1_norm * J1 + œÄÃÉ2_norm * J2)\n",
    "\n",
    "    if weight == 0 or weight == 1:\n",
    "        RE = œÄÃÉ1_norm * R1 + œÄÃÉ2_norm * R2\n",
    "    else:\n",
    "        RE = œÄÃÉ1_norm * R1 + œÄÃÉ2_norm * R2 + œÄÃÉ1_norm * np.log(\n",
    "            œÄÃÉ1_norm / weight) + œÄÃÉ2_norm * np.log(œÄÃÉ2_norm / (1 - weight))\n",
    "\n",
    "    RE_total = Œæp * RE\n",
    "\n",
    "    # Step (6) and (7) Formulating HJB False Transient parameters\n",
    "    # See remark 2.1.4 for more details\n",
    "    A = -Œ¥ * np.ones(R_mat.shape)\n",
    "    B_r = -e_star + œà0 * (j ** œà1) * np.exp(œà1 * (K_mat - R_mat)) - 0.5 * (œÉùò≥ ** 2)\n",
    "    B_f = e_star * np.exp(R_mat)\n",
    "    B_k = Œºk + œï0 * np.log(1 + i * œï1) - 0.5 * (œÉùò¨ ** 2)\n",
    "    C_rr = 0.5 * œÉùò≥ ** 2 * np.ones(R_mat.shape)\n",
    "    C_ff = np.zeros(R_mat.shape)\n",
    "    C_kk = 0.5 * œÉùò¨ ** 2 * np.ones(R_mat.shape)\n",
    "    D = Œ¥ * Œ∫ * np.log(e_star) + Œ¥ * Œ∫ * R_mat + Œ¥ * (1 - Œ∫) * (np.log(Œ± - i - j) + K_mat) + drift_distort + RE_total # + I_term \n",
    "\n",
    "    # Step (8) solving linear system using a conjugate-gradient method in C++\n",
    "    # See remark 2.1.5, 2.1.6 for more details\n",
    "    out = PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, v0, Œµ, solverType = 'False Transient')\n",
    "\n",
    "    out_comp = out[2].reshape(v0.shape,order = \"F\")\n",
    "    \n",
    "    # Calculating PDE error and False Transient error\n",
    "    PDE_rhs = A * v0 + B_r * v0_dr + B_f * v0_df + B_k * v0_dk + C_rr * v0_drr + C_kk * v0_dkk + C_ff * v0_dff + D\n",
    "    PDE_Err = np.max(abs(PDE_rhs))\n",
    "    FC_Err = np.max(abs((out_comp - v0)))\n",
    "    if episode % 100 == 0:\n",
    "        print(\"Episode {:d}: PDE Error: {:.10f}; False Transient Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\" .format(episode, PDE_Err, FC_Err, out[0], out[1]))\n",
    "    episode += 1\n",
    "    \n",
    "    # step 9: keep iterating until convergence\n",
    "    v0 = out_comp\n",
    "\n",
    "print(\"Episode {:d}: PDE Error: {:.10f}; False Transient Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\" .format(episode, PDE_Err, FC_Err, out[0], out[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 540  660]\n",
      " [1080 1320]\n",
      " [1620 1980]]\n",
      "[[ 24  46  69]\n",
      " [ 57  79 102]]\n",
      "[[ 57  67  78]\n",
      " [100 110 121]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([12, 24, 36])   \n",
    "w = np.array([45, 55])  \n",
    "\n",
    "print(np.reshape(v, (3, 1)) * w) \n",
    "\n",
    "X = np.array([[12, 22, 33], [45, 55, 66]]) \n",
    "\n",
    "print(X + v)\n",
    "\n",
    "print((X.T + w).T) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
